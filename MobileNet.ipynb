{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkyCP12haRukwOpwN0raV4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohaidAhmed/DR-Train-Dataset/blob/main/MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9MSYvYDhERh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from keras import layers\n",
        "from tensorflow.keras import applications \n",
        "from keras.applications import MobileNetV2\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('../input/valid-and-test-ta/x_train_8.csv')\n",
        "valid_df = pd.read_csv('../input/valid-and-test-ta/x_valid_8.csv')\n",
        "print(train_df.shape)\n",
        "print(valid_df.shape)\n",
        "train_df.head()\n",
        "\n",
        "train_df['diagnosis'].value_counts()\n",
        "train_df['diagnosis'].hist()"
      ],
      "metadata": {
        "id": "7yESy4QJhShz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_samples(df, columns=4, rows=3):\n",
        "    fig=plt.figure(figsize=(5*columns, 4*rows))\n",
        "\n",
        "    for i in range(columns*rows):\n",
        "        image_path = df.loc[i,'id_code']\n",
        "        image_id = df.loc[i,'diagnosis']\n",
        "        img = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{image_path}.png')\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        fig.add_subplot(rows, columns, i+1)\n",
        "        plt.title(image_id)\n",
        "        plt.imshow(img)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "\n",
        "display_samples(train_df)"
      ],
      "metadata": {
        "id": "dfsXP47AhpcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#resample\n",
        "from sklearn.utils import resample\n",
        "X=train_df\n",
        "normal=X[X.diagnosis==0]\n",
        "mild=X[X.diagnosis==1]\n",
        "moderate=X[X.diagnosis==2]\n",
        "severe=X[X.diagnosis==3]\n",
        "pdr=X[X.diagnosis==4]\n",
        "\n",
        "#downsampled\n",
        "mild = resample(mild,\n",
        "                replace=True, # sample with replacement\n",
        "                n_samples=700, # match number in majority class\n",
        "                random_state=2020) # reproducible results\n",
        "moderate = resample(moderate,\n",
        "                    replace=False, # sample with replacement\n",
        "                    n_samples=700, # match number in majority class\n",
        "                    random_state=2020) # reproducible results\n",
        "severe = resample(severe,\n",
        "                  replace=True, # sample with replacement\n",
        "                  n_samples=700, # match number in majority class\n",
        "                  random_state=2020) # reproducible results\n",
        "normal = resample(normal,\n",
        "                  replace=False, # sample with replacement\n",
        "                  n_samples=700, # match number in majority class\n",
        "                  random_state=2020) # reproducible results\n",
        "pdr = resample(pdr,\n",
        "               replace=True, # sample with replacement\n",
        "               n_samples=700, # match number in majority class\n",
        "               random_state=2020) # reproducible results    \n",
        "\n",
        "# combine minority and downsampled majority\n",
        "sampled = pd.concat([normal, mild, moderate, severe, pdr])\n",
        "\n",
        "train_df = sampled\n",
        "train_df = train_df.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "eow85Bghh_Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, desired_size=224):\n",
        "    im = Image.open(image_path)\n",
        "    im = im.resize((desired_size, )*2, resample=Image.BILINEAR)\n",
        "    \n",
        "    return im\n",
        "\n",
        "N = train_df.shape[0]\n",
        "x_train = np.empty((N, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "for i, image_id in enumerate(tqdm(train_df['id_code'])):\n",
        "    x_train[i, :, :, :] = preprocess_image(\n",
        "        f'../input/aptos2019-blindness-detection/train_images/{image_id}.png'\n",
        "    )\n",
        "    \n",
        "N = valid_df.shape[0]\n",
        "x_val = np.empty((N, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "for i, image_id in enumerate(tqdm(valid_df['id_code'])):\n",
        "    x_val[i, :, :, :] = preprocess_image(\n",
        "        f'../input/aptos2019-blindness-detection/train_images/{image_id}.png'\n",
        "    )"
      ],
      "metadata": {
        "id": "NxZQzXZXiA1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_df['diagnosis']\n",
        "y_val = valid_df['diagnosis']\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "cvXg20sFiEC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "def create_datagen():\n",
        "    return ImageDataGenerator(\n",
        "        zoom_range=0.1,  # set range for random zoom\n",
        "        rotation_range = 360,\n",
        "        fill_mode='constant',\n",
        "        cval=0.,\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True,  # randomly flip images\n",
        "    )\n",
        "\n",
        "# Using generator\n",
        "data_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2019)"
      ],
      "metadata": {
        "id": "rqo3oZTriHJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics(Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.val_kappas = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        X_val, y_val = self.validation_data[:2]\n",
        "        \n",
        "        y_pred = self.model.predict(X_val)\n",
        "        y_pred = np.clip(y_pred,0,4)\n",
        "        y_pred = y_pred.astype(int)\n",
        "\n",
        "        _val_kappa = cohen_kappa_score(\n",
        "            y_val,\n",
        "            y_pred, \n",
        "            weights='quadratic'\n",
        "        )\n",
        "\n",
        "        self.val_kappas.append(_val_kappa)\n",
        "\n",
        "        print(f\"val_kappa: {_val_kappa:.4f}\")\n",
        "        \n",
        "        if _val_kappa == max(self.val_kappas):\n",
        "            print(\"Validation Kappa has improved. Saving model.\")\n",
        "            self.model.save('model.h5')\n",
        "\n",
        "        return\n",
        "    \n",
        "kappa_metrics = Metrics()"
      ],
      "metadata": {
        "id": "BMi6dFidiKs6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}